{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "backed-mouth",
   "metadata": {},
   "source": [
    "# RISProcess\n",
    "## Signal Processing Workflow Control\n",
    "\n",
    "By William Jenkins\n",
    "<br>wjenkins [at] ucsd [dot] edu\n",
    "<br>Scripps Institution of Oceanography, UC San Diego\n",
    "<br>January 2021\n",
    "\n",
    "**Introduction & Considerations**\n",
    "<br>This notebook provides a general framework for how to use RISCluster.  Within the notebook, you can configure the workflow parameters and save the configuration files to disk.  These files are required to run the RISCluster processing scripts.  Once the configuration files are saved to disk, copy the `script code` provided by the notebook, and paste them into Terminal.  Ensure that the appropriate Python environment is activated, and that the paths and working directories between the notebook and Terminal are consistent.\n",
    "\n",
    "\n",
    "\n",
    "**Contents:**\n",
    "<br>1. Download Data\n",
    "<br>2. Pre-process Data\n",
    "<br>3. Detect Events & Build Catalogue\n",
    "<br>4. Build HDF Database from Catalogue</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spectacular-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "from RISProcess.io import config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-rainbow",
   "metadata": {},
   "source": [
    "## 1 Download Data\n",
    "Not yet implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "floral-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = './outputs'\n",
    "datapath = f\"{basepath}/raw\"\n",
    "configpath = basepath\n",
    "\n",
    "parameters = {\n",
    "    'start': '20141201T0000',\n",
    "    'stop': '20141203T0000',\n",
    "    'mode': 'download',\n",
    "    'datapath': datapath,\n",
    "    'network': 'XH',\n",
    "    'station': '*',\n",
    "    'channel': 'HH*',\n",
    "}\n",
    "config_file = config('w', path=configpath, parameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-march",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cooked-redhead",
   "metadata": {},
   "source": [
    "## 2 Pre-process Data\n",
    "In this workflow, raw seismic data is read from `datapath`, processed, and saved to `writepath` according to the file structure: `MSEED/Network/Station/Network.Station.Channel.Year.Yearday.mseed`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-competition",
   "metadata": {},
   "source": [
    "### 2.1 Set processing configuration parameters and create configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hairy-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/Volumes/RISData'\n",
    "basepath = './outputs'\n",
    "writepath = f\"{basepath}/MSEED\"\n",
    "configpath = basepath\n",
    "\n",
    "parameters = {\n",
    "    'start': '20141201T0000',\n",
    "    'stop': '20141203T0000',\n",
    "    'mode': 'preprocess',\n",
    "    'sourcepath': datapath,\n",
    "    'writepath': writepath,\n",
    "    'network': 'XH',\n",
    "    'channel': 'HHZ',\n",
    "    'taper': 60,\n",
    "    'prefeed': 60,\n",
    "    'fs2': 50,\n",
    "    'cutoff': '3, 20',\n",
    "    'output': 'acc',\n",
    "    'prefilt': '0.004, 0.01, 500, 1000',\n",
    "    'waterlevel': 14,\n",
    "    'detector': 'z',\n",
    "    'on': 8,\n",
    "    'off': 4,\n",
    "    'num_workers': 4\n",
    "}\n",
    "config_file = config('w', path=configpath, parameters=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-brooks",
   "metadata": {},
   "source": [
    "### 2.2 Process data.\n",
    "To execute the script, run the following code in terminal with the appropriate `conda` environment activated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "challenging-proof",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "`process /Users/williamjenkins/Research/Workflows/RIS_Seismic_Processing/Source/RISProcess/outputs/config_preprocess.ini`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(f\"`process {config_file}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-memory",
   "metadata": {},
   "source": [
    "## 3 Detect Events & Build Catalogue\n",
    "In this workflow, raw seismic data in `datapath` is processed in 24-hour segments, and an event detection algorithm is applied.  The results of the event detector are compiled into a catalogue that is saved to disk at `writepath`.  This catalogue serves as a useful pointer for follow-on processing of events of interest, rather than continuous data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-interface",
   "metadata": {},
   "source": [
    "### 3.1 Set processing configuration parameters and create configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bound-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/Volumes/RISData'\n",
    "basepath = './outputs'\n",
    "writepath = basepath\n",
    "configpath = basepath\n",
    "\n",
    "parameters = {\n",
    "    'start': '20141201T0000',\n",
    "    'stop': '20141203T0000',\n",
    "    'mode': 'detect',\n",
    "    'sourcepath': datapath,\n",
    "    'writepath': writepath,\n",
    "    'network': 'XH',\n",
    "    'channel': 'HHZ',\n",
    "    'taper': 60,\n",
    "    'prefeed': 60,\n",
    "    'fs2': 50,\n",
    "    'cutoff': '3, 20',\n",
    "    'output': 'acc',\n",
    "    'prefilt': '0.004, 0.01, 500, 1000',\n",
    "    'waterlevel': 14,\n",
    "    'detector': 'z',\n",
    "    'on': 8,\n",
    "    'off': 4,\n",
    "    'num_workers': 4\n",
    "}\n",
    "config_file = config('w', path=configpath, parameters=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-bowling",
   "metadata": {},
   "source": [
    "### 3.2 Run script.\n",
    "To execute the script, run the following code in terminal with the appropriate `conda` environment activated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "killing-duncan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "`process /Users/williamjenkins/Research/Workflows/RIS_Seismic_Processing/Source/RISProcess/outputs/config_cat2h5.ini`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(f\"`process {config_file}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-netherlands",
   "metadata": {},
   "source": [
    "### 3.3 Clean catalogue.\n",
    "Remove duplicate detections, and if desired, detections that occur within a window (s) following an initial detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "behavioral-italian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "`cleancat ./outputs/catalogue.csv --dest ./outputs/catalogue2.csv --window 10`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 10\n",
    "\n",
    "md(f\"`cleancat {basepath}/catalogue.csv --dest {basepath}/catalogue2.csv --window {window}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-satisfaction",
   "metadata": {},
   "source": [
    "## 4 Build HDF Database from Catalogue\n",
    "In this workflow, a catalogue of detections at `catalogue` is used to process raw seismic data in `datapath`.  In addition to pre-processing, the traces, spectrograms, and metadata of the detections are saved to an HDF database located at `writepath`.  Because this workflow is implemented in parallel and results are returned asynchronously, a new catalogue is saved to `writepath.csv` that corresponds to the indexing within the HDF dataset.  The index within `writepath.csv` corresponds to the original catalogue at `catalogue`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-burner",
   "metadata": {},
   "source": [
    "### 4.1 Set processing configuration parameters and create configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "three-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/Volumes/RISData'\n",
    "basepath = './outputs'\n",
    "writepath = f\"{basepath}/RISData.h5\"\n",
    "catalogue = f\"{basepath}/catalogue2.csv\"\n",
    "configpath = basepath\n",
    "\n",
    "parameters = {\n",
    "    'start': '20141201T0000',\n",
    "    'stop': '20141203T0000',\n",
    "    'mode': 'cat2h5',\n",
    "    'sourcepath': datapath,\n",
    "    'writepath': writepath,\n",
    "    'catalogue': catalogue,\n",
    "    'network': 'XH',\n",
    "    'channel': 'HHZ',\n",
    "    'taper': 10,\n",
    "    'prefeed': 10,\n",
    "    'fs2': 50,\n",
    "    'cutoff': '3, 20',\n",
    "    'T_seg': 4,\n",
    "    'NFFT': 256,\n",
    "    'tpersnap': 0.4,\n",
    "    'overlap': 0.9,\n",
    "    'output': 'acc',\n",
    "    'prefilt': '0.004, 0.01, 500, 1000',\n",
    "    'waterlevel': 14,\n",
    "    'detector': 'z',\n",
    "    'on': 8,\n",
    "    'off': 4,\n",
    "    'det_window': 5,\n",
    "    'num_workers': 4\n",
    "}\n",
    "config_file = config('w', path=configpath, parameters=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-indie",
   "metadata": {},
   "source": [
    "### 4.2 Run script.\n",
    "To execute the script, run the following code in terminal with the appropriate `conda` environment activated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "italic-assets",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "`process /Users/williamjenkins/Research/Workflows/RIS_Seismic_Processing/Source/RISProcess/outputs/config_cat2h5.ini`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(f\"`process {config_file}`\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RISProcess",
   "language": "python",
   "name": "risprocess"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
